{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1ux2pKyBCcLGyq3RHPsWu707sl-DRANuZ","authorship_tag":"ABX9TyPUpskGt9ZtFUrfODhHoVKB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":11,"metadata":{"id":"PMtwttv4ZJZf","executionInfo":{"status":"ok","timestamp":1732838889847,"user_tz":300,"elapsed":221,"user":{"displayName":"Niharika Sravan","userId":"12216456039336158799"}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import os, glob\n","import math\n","\n","lcs = pd.read_csv('/content/drive/Othercomputers/My Mac/Work/Fermi_GRBs/lcs.csv')\n"]},{"cell_type":"code","source":["if torch.cuda.is_available():\n","       device = torch.device(\"cuda\")\n","       print(\"GPU is available\")\n","else:\n","       device = torch.device(\"cpu\")\n","       print(\"GPU is not available, using CPU instead\")\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u3KPtFv0PW2Q","executionInfo":{"status":"ok","timestamp":1732838890937,"user_tz":300,"elapsed":246,"user":{"displayName":"Niharika Sravan","userId":"12216456039336158799"}},"outputId":"3a55736a-58dd-4063-9660-47d0d06f8c98"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is available\n"]}]},{"cell_type":"code","source":["channels = ['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'na', 'nb', 'b1', 'b2']"],"metadata":{"id":"rENlFuCtZaqi","executionInfo":{"status":"ok","timestamp":1732838891220,"user_tz":300,"elapsed":3,"user":{"displayName":"Niharika Sravan","userId":"12216456039336158799"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Fill missing channels with zeros\n","for channel in channels:\n","  lcs[channel].fillna(0.0, inplace=True)\n","\n","time_series_list = []\n","grouped = lcs.groupby('burst')\n","for burst, group in grouped:\n","    time_series_data = group[channels].values\n","    time_series_tensor = torch.tensor(time_series_data, dtype=torch.float32)\n","    time_series_list.append(time_series_tensor)\n","\n","class TimeSeriesDataset(Dataset):\n","    def __init__(self, time_series_list):\n","        self.time_series_list = time_series_list\n","\n","    def __len__(self):\n","        return len(self.time_series_list)\n","\n","    def __getitem__(self, idx):\n","        return self.time_series_list[idx]\n","\n","# Pad sequences to the same length\n","def collate_fn(batch):\n","    batch = nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.0)\n","    return batch\n","\n","# Define the Positional Encoding Class\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, model_dim, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        pe = torch.zeros(max_len, model_dim)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, model_dim, 2).float() * (-math.log(10000.0) / model_dim))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(0), :]\n","        return x\n","\n","# Define the Transformer Encoder\n","class TransformerEncoder(nn.Module):\n","    def __init__(self, input_dim, model_dim, num_heads, num_layers, dropout=0.1):\n","        super(TransformerEncoder, self).__init__()\n","        self.embedding = nn.Linear(input_dim, model_dim)\n","        self.positional_encoding = PositionalEncoding(model_dim)\n","        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout)\n","        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n","\n","    def forward(self, src):\n","        src = self.embedding(src)\n","        src = self.positional_encoding(src)\n","        output = self.transformer_encoder(src)\n","        return output\n","\n","# Define the Transformer Decoder\n","class TransformerDecoder(nn.Module):\n","    def __init__(self, model_dim, output_dim, num_heads, num_layers, dropout=0.1):\n","        super(TransformerDecoder, self).__init__()\n","        decoder_layer = nn.TransformerDecoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout)\n","        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n","        self.output_layer = nn.Linear(model_dim, output_dim)\n","\n","    def forward(self, tgt, memory):\n","        output = self.transformer_decoder(tgt, memory)\n","        output = self.output_layer(output)\n","        return output\n","\n","# Define the Autoencoder\n","class TransformerAutoencoder(nn.Module):\n","    def __init__(self, input_dim, model_dim, num_heads, num_layers, dropout=0.1):\n","        super(TransformerAutoencoder, self).__init__()\n","        self.encoder = TransformerEncoder(input_dim, model_dim, num_heads, num_layers, dropout)\n","        self.decoder = TransformerDecoder(model_dim, input_dim, num_heads, num_layers, dropout)\n","\n","    def forward(self, src):\n","        memory = self.encoder(src)\n","        tgt = self.encoder.embedding(src)\n","        tgt = self.encoder.positional_encoding(tgt)\n","        output = self.decoder(tgt, memory)\n","        return output, memory\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QF_QF6GFieeX","executionInfo":{"status":"ok","timestamp":1732838891956,"user_tz":300,"elapsed":164,"user":{"displayName":"Niharika Sravan","userId":"12216456039336158799"}},"outputId":"49001ab3-65ae-4fd2-a3ff-d02b70564827"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-09538db39e4d>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  lcs[channel].fillna(0.0, inplace=True)\n"]}]},{"cell_type":"code","source":["# Parameters\n","input_dim = 14\n","model_dim = 64\n","num_heads = 8\n","num_layers = 4\n","batch_size = 16\n","num_epochs = 50\n","learning_rate = 0.001\n","\n","# Initialize the autoencoder\n","autoencoder = TransformerAutoencoder(input_dim, model_dim, num_heads, num_layers)\n","\n","# Create the dataset and dataloader\n","dataset = TimeSeriesDataset(time_series_list)\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","\n","# Define the loss function and optimizer\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)\n"],"metadata":{"id":"gmcRF-DojbBa","executionInfo":{"status":"ok","timestamp":1732838936585,"user_tz":300,"elapsed":179,"user":{"displayName":"Niharika Sravan","userId":"12216456039336158799"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["autoencoder = autoencoder.to(device)"],"metadata":{"id":"nR7VnfTbPahK","executionInfo":{"status":"ok","timestamp":1732838937159,"user_tz":300,"elapsed":133,"user":{"displayName":"Niharika Sravan","userId":"12216456039336158799"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Training loop\n","for epoch in range(num_epochs):\n","    for batch in dataloader:\n","        # Original shape of batch: (batch_size, sequence_length, input_dim)\n","        # Permute to shape: (sequence_length, batch_size, input_dim)\n","        batch = batch.permute(1, 0, 2)\n","        batch = batch.to(device)\n","\n","        # Forward pass\n","        reconstructed, latent = autoencoder(batch)\n","\n","        # Compute the loss\n","        loss = criterion(reconstructed, batch)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3KqFQo9CjoHn","executionInfo":{"status":"ok","timestamp":1732839007240,"user_tz":300,"elapsed":69239,"user":{"displayName":"Niharika Sravan","userId":"12216456039336158799"}},"outputId":"6223902b-f0f5-476d-ca79-a43d2377c2d5"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/50], Loss: 1316924.3750\n","Epoch [2/50], Loss: 2618347.5000\n","Epoch [3/50], Loss: 1323944.6250\n","Epoch [4/50], Loss: 2073745.1250\n","Epoch [5/50], Loss: 1306518.8750\n","Epoch [6/50], Loss: 1224891.6250\n","Epoch [7/50], Loss: 1430387.0000\n","Epoch [8/50], Loss: 1604286.2500\n","Epoch [9/50], Loss: 1289956.1250\n","Epoch [10/50], Loss: 1163014.0000\n","Epoch [11/50], Loss: 1997914.7500\n","Epoch [12/50], Loss: 526818.7500\n","Epoch [13/50], Loss: 1345770.8750\n","Epoch [14/50], Loss: 1987190.8750\n","Epoch [15/50], Loss: 1208355.2500\n","Epoch [16/50], Loss: 1096158.8750\n","Epoch [17/50], Loss: 724359.8125\n","Epoch [18/50], Loss: 1298631.7500\n","Epoch [19/50], Loss: 1610448.0000\n","Epoch [20/50], Loss: 1109384.1250\n","Epoch [21/50], Loss: 1428247.0000\n","Epoch [22/50], Loss: 1249997.1250\n","Epoch [23/50], Loss: 2344485.5000\n","Epoch [24/50], Loss: 1264824.7500\n","Epoch [25/50], Loss: 1144072.7500\n","Epoch [26/50], Loss: 1722788.8750\n","Epoch [27/50], Loss: 1270925.6250\n","Epoch [28/50], Loss: 1089369.8750\n","Epoch [29/50], Loss: 1509540.3750\n","Epoch [30/50], Loss: 1670187.2500\n","Epoch [31/50], Loss: 1116654.0000\n","Epoch [32/50], Loss: 1536722.2500\n","Epoch [33/50], Loss: 1151586.0000\n","Epoch [34/50], Loss: 1447160.7500\n","Epoch [35/50], Loss: 796918.7500\n","Epoch [36/50], Loss: 2324391.2500\n","Epoch [37/50], Loss: 1849262.8750\n","Epoch [38/50], Loss: 1793431.2500\n","Epoch [39/50], Loss: 1333256.2500\n","Epoch [40/50], Loss: 1205807.2500\n","Epoch [41/50], Loss: 1122718.2500\n","Epoch [42/50], Loss: 940266.5625\n","Epoch [43/50], Loss: 1113355.8750\n","Epoch [44/50], Loss: 1078569.8750\n","Epoch [45/50], Loss: 1556904.3750\n","Epoch [46/50], Loss: 1361065.1250\n","Epoch [47/50], Loss: 791944.7500\n","Epoch [48/50], Loss: 1921175.8750\n","Epoch [49/50], Loss: 1805322.6250\n","Epoch [50/50], Loss: 785178.4375\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jNM00raWjtLy","executionInfo":{"status":"ok","timestamp":1732837771752,"user_tz":300,"elapsed":320,"user":{"displayName":"Niharika Sravan","userId":"12216456039336158799"}}},"execution_count":null,"outputs":[]}]}