{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 13988,
     "status": "ok",
     "timestamp": 1732842026610,
     "user": {
      "displayName": "Niharika Sravan",
      "userId": "12216456039336158799"
     },
     "user_tz": 300
    },
    "id": "PMtwttv4ZJZf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "lcs = pd.read_csv('lcs.csv')\n",
    "channels = ['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'na', 'nb', 'b1', 'b2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2187,
     "status": "ok",
     "timestamp": 1732842028796,
     "user": {
      "displayName": "Niharika Sravan",
      "userId": "12216456039336158799"
     },
     "user_tz": 300
    },
    "id": "QF_QF6GFieeX",
    "outputId": "cc6927b3-11fc-4f7e-fd91-ebcf4b88e1d6"
   },
   "outputs": [],
   "source": [
    "# Fill missing channels with zeros\n",
    "for channel in channels:\n",
    "  lcs[channel].fillna(0.0, inplace=True)\n",
    "\n",
    "time_series_list = []\n",
    "grouped = lcs.groupby('burst')\n",
    "for burst, group in grouped:\n",
    "    time_series_data = group[channels].values\n",
    "    time_series_tensor = torch.tensor(time_series_data, dtype=torch.float32)\n",
    "    time_series_list.append(time_series_tensor)\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, time_series_list):\n",
    "        self.time_series_list = time_series_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.time_series_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.time_series_list[idx]\n",
    "\n",
    "# Pad sequences to the same length\n",
    "def collate_fn(batch):\n",
    "    batch = nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.0)\n",
    "    return batch\n",
    "\n",
    "# Define the Positional Encoding Class\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, model_dim, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, model_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, model_dim, 2).float() * (-math.log(10000.0) / model_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "# Define the Transformer Encoder\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_layers, dropout=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, model_dim)\n",
    "        self.positional_encoding = PositionalEncoding(model_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src)\n",
    "        src = self.positional_encoding(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        return output\n",
    "\n",
    "# Define the Transformer Decoder\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, model_dim, output_dim, num_heads, num_layers, dropout=0.1):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=model_dim, nhead=num_heads, dropout=dropout)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "        self.output_layer = nn.Linear(model_dim, output_dim)\n",
    "\n",
    "    def forward(self, tgt, memory):\n",
    "        output = self.transformer_decoder(tgt, memory)\n",
    "        output = self.output_layer(output)\n",
    "        return output\n",
    "\n",
    "# Define the Autoencoder\n",
    "class TransformerAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, model_dim, num_heads, num_layers, dropout=0.1):\n",
    "        super(TransformerAutoencoder, self).__init__()\n",
    "        self.encoder = TransformerEncoder(input_dim, model_dim, num_heads, num_layers, dropout)\n",
    "        self.decoder = TransformerDecoder(model_dim, input_dim, num_heads, num_layers, dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        memory = self.encoder(src)\n",
    "        tgt = self.encoder.embedding(src)\n",
    "        tgt = self.encoder.positional_encoding(tgt)\n",
    "        output = self.decoder(tgt, memory)\n",
    "        return output, memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 153,
     "status": "ok",
     "timestamp": 1732842050772,
     "user": {
      "displayName": "Niharika Sravan",
      "userId": "12216456039336158799"
     },
     "user_tz": 300
    },
    "id": "gmcRF-DojbBa",
    "outputId": "5e2d2150-eacd-4fd0-e945-49916b5da7fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niharika/opt/anaconda3/envs/Fermi_GRBs/lib/python3.8/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "input_dim = 14\n",
    "model_dim = 32\n",
    "num_heads = 4\n",
    "num_layers = 2\n",
    "batch_size = 16\n",
    "num_epochs = 50\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Initialize the autoencoder\n",
    "autoencoder = TransformerAutoencoder(input_dim, model_dim, num_heads, num_layers)\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "dataset = TimeSeriesDataset(time_series_list)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KqFQo9CjoHn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1573701.8750\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        # Original shape of batch: (batch_size, sequence_length, input_dim)\n",
    "        # Permute to shape: (sequence_length, batch_size, input_dim)\n",
    "        batch = batch.permute(1, 0, 2)\n",
    "        reconstructed, latent = autoencoder(batch)\n",
    "        loss = criterion(reconstructed, batch)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1732837771752,
     "user": {
      "displayName": "Niharika Sravan",
      "userId": "12216456039336158799"
     },
     "user_tz": 300
    },
    "id": "jNM00raWjtLy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOVBNeb7B1ROrXNIXQUYfMo",
   "gpuType": "T4",
   "mount_file_id": "1ux2pKyBCcLGyq3RHPsWu707sl-DRANuZ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Fermi_GRBs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
